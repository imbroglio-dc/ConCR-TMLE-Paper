
#+TITLE: ConCR-TMLE R Paper
#+Author: David Chen, Thomas Gerds, Helene Rytgaard
#+Date: 
#+EMAIL: 
#+LANGUAGE:  en
#+OPTIONS: H:3 num:t toc:nil \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+OPTIONS: TeX:t LaTeX:t skip:nil d:nil todo:t pri:nil tags:not-in-toc author:nil
#+LaTeX_CLASS: Rnews-article
#+LaTeX_HEADER:\usepackage[utf8]{inputenc}
#+LaTeX_HEADER:\usepackage[T1]{fontenc}
#+LaTeX_HEADER:\usepackage{amsmath,amssymb,array}
#+LaTeX_HEADER:\usepackage{booktabs}
#+LaTeX_HEADER:\usepackage{natbib}
#+LaTeX_HEADER:\usepackage{listings}
#+LaTeX_HEADER:\newcommand{\J}{\ensuremath{J}}
#+LaTeX_HEADER:\newcommand{\1}{\ensuremath{\mathbf{1}}}
#+LaTeX_HEADER:\DeclareMathOperator*{\argmax}{argmax}
#+LaTeX_HEADER:\DeclareMathOperator*{\argmin}{argmin}
#+LaTeX_HEADER:\newcommand{\h}{\ensuremath{\lambda}}
#+LaTeX_HEADER:\newcommand{\indep}{\ensuremath{\perp\hspace*{-1.4ex}\perp}}
#+LaTeX_HEADER:\newcommand{\T}{\ensuremath{\widetilde{T}}}
#+LaTeX_HEADER:\newcommand{\X}{\ensuremath{{X}}}
#+LaTeX_HEADER:\renewcommand{\t}{\ensuremath{\Tilde{t}}}
#+LaTeX_HEADER:\newcommand{\ax}{\ensuremath{\mid a,\,{x}}}
#+LaTeX_HEADER:\newcommand{\aX}{\ensuremath{\mid A = a,\,{X}}}
#+LaTeX_HEADER:\newcommand{\AX}{\ensuremath{\mid A,\,{X}}}
#+LaTeX_HEADER:\newcommand{\x}{\ensuremath{{x}}}
#+LaTeX_HEADER:\newcommand{\trt}{\ensuremath{\pi^*}}
#+LaTeX_HEADER:\newcommand{\tk}{\ensuremath{\tau}}
#+LaTeX_HEADER:\newcommand{\lj}{\ensuremath{j}}
#+LaTeX_HEADER:\newcommand{\jj}{\ensuremath{k}}
#+LaTeX_HEADER:\newcommand{\g}{\ensuremath{\pi}}
#+setupfile:~/emacs-genome/snps/org-templates/setup-all-purpose.org
#+superman-export-target: pdf

#+begin_export latex
\abstract{
An abstract of less than 150 words.
}
#+end_export

* Introduction

* Data Structure

Consider a survival analysis on an interval $[0,\,t_{max}]$ with competing risks. Let \(T^a_j\) denote counterfactual time-to-event variables for event $j$ and intervention $a$, for competing events $j \in \mathcal{J} = \{1, 2, \dots, J\}$ and an intervention $a \in \mathcal{A}$. Our counterfactual data structure can then be denoted by
\[(T^a_j,\;\X\,:\;a\in\mathcal{A},\;j\in\mathcal{J})\]
where $\X \in \mathbb{R}^d$ is a \(d\)-dimensional vector of baseline covariates. For a single time-point binary intervention, as in many randomized control trials, $\mathcal{A} = \{0, 1\}$ and the corresponding counterfactual data is 
\[ (T^1_j,\; T^0_j,\;\X\,: \;j\in\mathcal{J})\]

#+name: data
#+ATTR_LATEX: :options otherkeywords={}, deletekeywords={}
#+BEGIN_SRC R  :results output raw  :exports none  :session *R* :cache no  :eval always
library(data.table)
devtools::load_all("/Shared/Projects/ConCR-TMLE/")
set.seed(123456)
n <- 100
A <- rbinom(n, 1, .3)
L1 <- rnorm(n, 0, 1)
L3 <- runif(n, 0, 5)
L2 <- as.factor(rbinom(n, 5, 0.6))
T.j1.a1 <- rweibull(n, 1, 1)
T.j1.a0 <- rweibull(n, 1, 1.2)
T.j2.a1 <- rweibull(n, 1.3, 1)
T.j2.a0 <- rweibull(n, 1.3, .9)
C <- rexp(n, 1.8)

T.A <- pmin(T.j1.a1*(A == 1) + T.j1.a0*(A == 0),
            T.j2.a1*(A == 1) + T.j2.a0*(A == 0))
T.tilde <- pmin(T.A, C)
Delta <- as.numeric(T.A <= C)
counterfactuals <- data.table(T.j1.a0 = T.j1.a0, T.j1.a1 = T.j1.a1,
                              T.j2.a0 = T.j2.a0, T.j2.a1 = T.j2.a1,
                              L1 = L1, L2 = L2, L3 = L3)
observed <- data.table(T.tilde = T.tilde, Delta = Delta,
                       A = A, L1 = L1, L2 = L2, L3 = L3)
#+END_SRC

#+ATTR_LATEX: :options otherkeywords={}, deletekeywords={}
#+BEGIN_SRC R  :results output raw drawer  :exports code :session *R* :cache yes
head(counterfactuals)
#+END_SRC

#+ATTR_LATEX: :options otherkeywords={}, deletekeywords={}
#+BEGIN_SRC R  :results output raw drawer  :exports results :session *R* :cache yes
Publish::org(head(counterfactuals))
#+END_SRC

#+RESULTS[(2022-03-28 10:20:39) fe49e0feb953623f939e4b035acea61eec059b53]:
:results:
|   |   T.j1.a0 |   T.j1.a1 |   T.j2.a0 |   T.j2.a1 |         L1 | L2 |        L3 |
|---+-----------+-----------+-----------+-----------+------------+----+-----------|
| 1 | 0.1599887 | 0.4906215 | 0.5399409 | 0.5803671 | -1.7677221 |  4 | 3.0093952 |
| 2 | 1.1369533 | 1.9210028 | 0.2375033 | 0.9133089 | -0.4916921 |  0 | 0.3294865 |
| 3 | 0.3447736 | 1.2538906 | 0.4779721 | 0.8540658 |  0.3214659 |  3 | 4.1630246 |
| 4 | 4.6631762 | 0.3718961 | 1.5650534 | 0.2485393 |  1.4606608 |  3 | 1.5313713 |
| 5 | 0.1430018 | 0.5951058 | 0.3003895 | 0.9765322 |  1.5372426 |  2 | 1.5580743 |
| 6 | 1.8419819 | 3.9131870 | 1.8517334 | 3.0117075 | -0.3395685 |  4 | 0.8455748 |
:end:

Let $O$ denote the corresponding coarsened observed data where $O \sim P_0$. The observed data would include the time-to-censoring $C$, and observed intervention $A$. The time to first event (censoring or otherwise) we denote as $\T = \min(C,\; T_j\,: \; j \in \mathcal{J})$ with $\Delta = (\argmin\limits_j T_j) \times \1(\min\limits_j T_j \leq C)$ marking which outcome is observed ($\Delta = 0$ being that censoring occurred). The observable right-censored survival data with competing events can then be represented as 
\[O = (\T,\;\Delta,\;A,\;\X)\]

#+ATTR_LATEX: :options otherkeywords={}, deletekeywords={}
#+BEGIN_SRC R  :results output raw  :exports code :session *R* :cache yes  
head(observed)
#+END_SRC

#+RESULTS[(2022-03-22 14:20:22) 4a48da3794d97a7a7c09463e52bb506dc2061bfd]:

#+ATTR_LATEX: :options otherkeywords={}, deletekeywords={}
#+BEGIN_SRC R  :results output raw drawer  :exports results :session *R* :cache yes  
Publish::org(head(observed))
#+END_SRC

#+RESULTS[(2022-03-22 14:20:27) 0b45fb93d486b18b77c6f449c81037590658f872]:
:results:
|   |    T.tilde | Delta | A |         L1 | L2 |        L3 |
|---+------------+-------+---+------------+----+-----------|
| 1 | 0.20711055 |     0 | 1 | -1.7677221 |  4 | 3.0093952 |
| 2 | 0.91147298 |     0 | 1 | -0.4916921 |  0 | 0.3294865 |
| 3 | 0.08374201 |     0 | 0 |  0.3214659 |  3 | 4.1630246 |
| 4 | 0.29772679 |     0 | 0 |  1.4606608 |  3 | 1.5313713 |
| 5 | 0.14300179 |     1 | 0 |  1.5372426 |  2 | 1.5580743 |
| 6 | 1.06839386 |     0 | 0 | -0.3395685 |  4 | 0.8455748 |
:end:

This observed data also allows the ``long-format'' formulation, where with single time-point intervention variable $A$ and baseline covariate vector $\X$, \[O = (N_j(t),\;N_c(t),\;A,\;\X\,:\, j\in\mathcal{J}, t \leq \T)\] Here $N_j(t) = \1(\T \leq t, \Delta = j)$ and $N_c(t) = \1(\T \leq t, \Delta = 0)$ denote counting processes for event $j$ and censoring respectively.

Under coarsening at random (CAR), the observed data likelihood can be factorized as
\begin{align*}
p(O) = p&(\X)\, \g(A \mid \X)\, \lambda_c(\T \AX)^{\1(\Delta = 0)} S_c(\T\text{-} \AX)\\
&\prod_{j=1}^{J} S(\T\text{-} \AX) \, \lambda_j(\T \AX)^{\1(\Delta = j)}
\end{align*}
where $\lambda_c(t \AX)$ is the hazard of the censoring process and $\lambda_j(t \AX)$ is the hazard of the $j^{th}$ event process. Additionally
\begin{align*}
    S_c(t \ax) &= \exp\left(-\int_{0}^{t} \lambda_c(s \ax) \,ds\right)
\intertext{while in a pure competing risks setting}
    S(t \ax) &= \exp\left(-\int_{0}^{t} \sum_{j=1}^{J} \lambda_j(s \ax) \,ds\right)
\intertext{and} 
    F_j(t \ax) &= \int_{0}^{t} S(s\text{-} \ax) \lambda_j(s \ax)\,ds\\
    &= \int_{0}^{t} \exp\bigg(-\int_{0}^{s} \sum_{j=1}^{J} \lambda_j(u \ax)\,du\bigg) \lambda_j(s \ax)\,ds.
\end{align*}

* Target Parameter
Given the identification assumptions of
\begin{enumerate}
\item Consistency : \(T = T^a\) when \(A = a\) for $a = 0,1$.
\item No unmeasured confounding: \(T^a \indep A \mid \X\) for $a = 0,1$.
\item Coarsening at random on censoring: \(T \indep C \AX\)
\end{enumerate}
the hypothetical distribution for data generated following a desired treatment regime involving $A \sim \trt(A \mid \X)$ and the prevention of the censoring process can be identified as
\[p^{\trt}(O) = p(\X)\, \trt(A \mid \X)\, \prod_{j=1}^{J} S(\T\text{-} \AX) \lambda_j(\T \AX)^{\1(\Delta = j)}\]
For a target parameter of the cause $\jj \in \J$ absolute risk at time $\tk$ under this treatment regime $\trt$, the corresponding efficient influence function is
\begin{align*}
    D^{*}_{\trt, \jj, \tk}(P)(O) &= \sum_{j = 1}^{J} \int_{0}^{\tk} \bigg[h_{\trt, \jj, j, \tk, s}(P)(O) \left(N_j(ds) - \1(\T \geq s)\,\lambda_j(s \AX)\right) \bigg] \,ds\\[2mm]
    &\hspace{2cm}+ \sum_{a=0,1} F_\jj(t \mid A = a, \X)\,\trt(a \mid X) - \Psi_{\trt, \jj, \tk}(P_0)
\intertext{with the clever covariate}
h_{\trt, \jj, j, \tk, s}(P)(O) &= \frac{\trt(A \mid \X)\, \1(s \leq \tk)}{\g(A \mid \X) S_c(s\text{-} \AX)} \left(\1(\delta = \jj) - \frac{F_\jj(\tk \AX) - F_\jj(s \AX)}{S(s \AX)}\right)
\end{align*}

As the efficient influence function and clever covariates depend on the treatment distribution \g, the censoring survival function $S_c$, and the event cause-specific hazards $\lambda = (\lambda_\lj : j = 1, ..., J)$, we will in subsequent sections use the following alternative notation for clarity when appropriate:
\begin{align*}
D^{*}_{\trt, \jj, \tk}(\lambda, \g, S_c)(O) &= D^{*}_{\trt, \jj, \tk}(P)(O)\\
h_{\trt, \jj, j, \tk, s}(\lambda, \g, S_c)(O)&= h_{\trt, \jj, j, \tk, s}(P)(O)
\end{align*}

Therefore, to efficiently estimate survival-curve derived estimands such as the cause-specific absolute risks, the components of the data distribution that must be estimated are $\g(A \mid \X)$, $S_c(t \AX)$, $\lambda_j(t \AX)$, $F_j(t \AX)$, and $S(t \AX)$

* Estimation
** Cross-Validation Specification
Let $Q_n = \{O_i\}_{i=1}^n$ be an observed sample of $n$ i.i.d observations of $O \sim P_0$. For $V\text{-fold}$ cross validation, let $B_n = \{1, ... , V\}^n$ be a random vector that assigns the $n$ observations into $V$ validation folds. For each $v \in \{1, ..., V\}$ we then define training set $Q^\mathcal{T}_v = \{O_i : B_n(i) = v\}$ with the corresponding validation set $Q^\mathcal{V}_v = \{O_i : B_n(i) \neq v\}$.

*** Stratified Cross-Validation
#+ATTR_LATEX: :options otherkeywords={}, deletekeywords={}
#+BEGIN_SRC R  :results output raw drawer  :exports both :session *R* :cache yes
StrataIDs <- factor(paste(observed[["A"]], observed[["Delta"]]))
CVFolds <- origami::make_folds(n = observed,
                               fold_fun = origami::folds_vfold,
                               strata_ids = StrataIDs)
#+END_SRC

** Propensity Score Estimation
For the true conditional distribution of $A$ given $\X$, $\g_0(\cdot \mid \X)$, and $\Hat{\g} : Q_n \to \Hat{\g}(Q_n)$, let $L_\g$ be a loss function such that the risk $\mathbb{E}_0\left[L_\g(\Hat{\g}, O)\right]$ is minimized when $\Hat{\g} = \g_0$. For instance, with a binary $A$, we may specify the negative log loss $L_\g(\Hat{\g}, O) = \text{-}\log\left(\Hat{\g}(1 \mid \X)^A \; \Hat{\g}(0 \mid \X))^{1-A}\right)$. We can then define the discrete superlearner selector which chooses from a set of candidate models $\mathcal{M_\g}$ the candidate propensity score model that has minimal cross validated risk 
\[ \Hat{\g}^{SL} = \argmin_{\Hat{\g} \in \mathcal{M}_\g} \sum_{v = 1}^{V} P_{Q^\mathcal{V}_v} \; L_\g(\Hat{\g}(Q^\mathcal{T}_v), Q^\mathcal{V}_v)\]

This discrete superlearner model \(\Hat{\g}^{SL}\) is then fitted on the full observed data \(Q_n\) and used to estimate \(\g_0(A \mid \X)\)

#+ATTR_LATEX: :options otherkeywords={}, deletekeywords={}
#+BEGIN_SRC R  :results output raw  :exports both  :session *R* :cache yes
CovDataTable <- observed[, -c("T.tilde", "Delta", "A")]
Models <- list("Trt" = sl3::make_learner(sl3:::Lrnr_glm))
Intervention <- list(
  "A=1" = list("intervention" = function(a, L) rep_len(1, length(a)),
               "g.star" = function(a, L) {as.numeric(a == 1)}),
  "A=0" = list("intervention" = function(a, L) rep_len(0, length(a)),
               "g.star" = function(a, L) {as.numeric(a == 0)})
)

RegsOfInterest <- getRegsOfInterest(Intervention = Intervention,
                                    Treatment = observed[["A"]],
                                    CovDataTable = CovDataTable)

PropScores <- getPropScore(Treatment = observed[["A"]],
                           CovDataTable = CovDataTable,
                           Models = Models,
                           MinNuisance = 0.05,
                           RegsOfInterest = RegsOfInterest,
                           PropScoreBackend = "sl3",
                           CVFolds = CVFolds)
#+END_SRC

** Hazard Estimation
Let \(\lambda_{0,\,\delta}\) be the true censoring and cause-specific hazards when \(\delta = 0\) and \(\delta = 1, \dots, J\) respectively. Let \(\mathcal{M}_\delta\) for \(\delta = 0, \dots, J\) be the sets of candidate models, $\{\Hat{\lambda}_\delta : Q_n \to \Hat{\lambda}_\delta(Q_n)\}$, for the censoring and cause-specific hazards and let $L_\delta$ be loss functions such that the risks $\mathbb{E}_0\left[L_\delta(\Hat{\lambda}_\delta, O)\right]$ are minimized when $\Hat{\lambda}_\delta = \lambda_{0,\,\delta}$, for instance log likelihood loss. We can then define the discrete superlearner selectors for each \(\delta\) which choose from the set of candidate models $\mathcal{M_\delta}$ the candidate propensity score model that has minimal cross validated risk 
\[ \Hat{\lambda}_\delta^{SL} = \argmin_{\Hat{\lambda}_\delta \in \mathcal{M}_\delta} \sum_{v = 1}^{V} P_{Q^\mathcal{V}_v} \; L_\g(\Hat{\lambda}_\delta(Q^\mathcal{T}_v), Q^\mathcal{V}_v)\]

These discrete superlearner selections \(\Hat{\lambda}_\delta^{SL}\) are then fitted on the full observed data \(Q_n\) and used to estimate \(\lambda_\delta(t \AX), \, F_\delta(t \AX),\, S(t \AX), \text{ and } S_c(t\text{-} \AX)\) for \(j = 1,\dots, J\).

#+ATTR_LATEX: :options otherkeywords={}, deletekeywords={}
#+BEGIN_SRC R  :results output raw drawer  :exports both  :session *R* :cache yes  

#+END_SRC

*** Lagged Censoring Survival
Let \(\mathcal{S}\) be the set containing all target and observed event times. Then for all \(s \,\in\, \mathcal{S}\) we compute
\[ \Hat{S}_c(s\text{-} \AX) = \prod_{t \in\mathcal{S}: t < s} \left(1 - \Hat{\lambda}_0^{SL}(t \AX)\right) \]

*** Cause-Specific Hazards, Event-Free Survival, and Cause-Specific Absolute Risks
For \(\lj = 1,\dots,J\) and \(s \,\in\, \mathcal{S}\), the super learner selections \(\Hat\lambda_\lj^{SL}\) are fit on the full observed data $Q_n$, and used to compute the event free survival
\begin{align*}
\Hat S(s \AX) &= \exp\left(\text{-} \sum_{t \in \mathcal{S}: t \leq s} \sum_{j = 1}^{J} \Hat\lambda^{SL}_j(t \AX) \right)
\intertext{cause-specific absolute risks}
\Hat F_\lj(s \AX) &= \sum_{t \in \mathcal{S}: t \leq s} \Hat S(t \AX) \, \Hat\lambda^{SL}_\lj(t \AX)
\end{align*}

* Computing the Efficient Influence Function
For each desired treatment regime \(\trt\), each target time \tk, and each target event \jj, the efficient influence functions for each individual are computed in parts.

** Clever Covariate Nuisance Weight
For every \(s \,\in\, \mathcal{S}\)
\begin{align*}
     \widehat{NW}_s = \frac{1}{\Hat\g^{SL}(a \mid \x) \Hat S_c(s\text{-} \ax)}
\end{align*}

1 nuisance weight for every individual at every time \(s \,\in\, \mathcal{S}\)

** Clever Covariate \(h_{\trt, \jj, j, \tk, s}\)
The stored cause-specific hazards \(\Hat\lambda^{SL}_\lj(s \ax)\) and event-free survival \(\Hat S(s \ax)\) are used to calculate the cause-specific absolute risks \(\Hat F_\lj(s \ax)\), then combined with the nuisance weight to calculate the clever covariates.
\begin{align*}
    h_{\trt,\, \jj,\, j,\, \tk,\, s}(\Hat \lambda, \Hat \g, \Hat S_c)(O) = \trt(a \mid \x)\, \1(s \leq \tk)
\times \widehat{NW}_s \times \left(\1(\delta = \jj) - \frac{F_\jj(\tk \ax) - F_\jj(s \ax)}{S(s \ax)}\right)
\end{align*}

1 clever covariate for every individual, for every regime of interest, for every target event, for every target time, at every time \(s \,\in\, \mathcal{S}\).

** Estimating the EIC
The sum over time and sum over events are done per individual. The addition of the absolute risk and subtraction of the target estimand are done later, outside of the loop over individuals.
\begin{align*}
    D^*_{\trt, \jj, \tk}(\Hat \lambda, \Hat \g, \Hat S_c)(O) &= \sum_{j = 1}^{J} \sum_{s = t_1}^{\tk \wedge \T} \;  h_{\trt,\, \jj,\, j,\, \tk, s}(\Hat \lambda, \Hat \g, \Hat S_c)(O) \times \left(\1(\Delta = \jj, \T = s) - \1(\T \geq s)\,\lambda_j(s \AX)\right)\\[2mm]
    &\hspace{2cm} {\color{red}+ \sum_{a\,\in\,\mathcal{A}} F_\jj(\tk \mid A = a, \X)\,\trt(a \mid \X) - \Psi_{\trt, \jj, \tk}(P_0)}
\end{align*}

1 EIC estimate for every individual, every regime of interest, every target event, and every target time.

* TMLE one-step update
Let \(D^*\) be the vector of efficient influence functions
\begin{align*}
D^{*}(\lambda, \g, S_c)(O) &= \left(D^*_{\trt, \jj, \tk}(\lambda, \g, S_c)(O) : \trt \in \mathcal{A}, \jj \in \mathcal{J}, \tk \in [0, t_{max})\right)
\intertext{and let \(h_{j, s}\) be the vector of clever covariates}
h_{j, s}(\lambda, \g, S_c)(O) &= \left(h_{\trt, \jj, j, \tk, s}(\lambda, \g, S_c)(O) : \trt \in \mathcal{A}, \jj \in \mathcal{J}, \tk \in [0, t_{max})\right)
\end{align*}
The onestep TMLE update of the cause-specific hazards is 
\[ \Hat \lambda_{j, \epsilon^d}(t) = \Hat\lambda^{SL}_{j}(t) \, \exp\left(\sum_{i = 1}^{d}\frac{\left<\mathbb{P}_n D^*(\Hat \lambda_{\epsilon^i}, \Hat \g, \Hat S_c)(O),\; h_{j, s}(\Hat \lambda_{\epsilon^i}, \Hat \g, \Hat S_c)(O) \right>_{\Sigma}}{|| D^*(\Hat \lambda_{\epsilon^i}, \Hat \g, \Hat S_c)(O)||_{\Sigma}} \; \epsilon \right)\]
where
\[ \left<x, y\right>_{\Sigma} = x^\top \Sigma^{\text{ -}1} y \hspace{.5cm}, \hspace{.5cm} ||x||_{\Sigma} = \sqrt{x^\top \Sigma^{\text{ -}1} x} \]

The default value of $\epsilon$ in the software is 0.1, and the algorithm stops when
\[\mathbb{P}_n D^*(\Hat \lambda_{\epsilon^i}, \Hat \g, \Hat S_c)(O) \leq \frac{\sqrt{\mathbb{P}_n \left[D^*(\Hat \lambda_{\epsilon^i}, \Hat \g, \Hat S_c)(O)^2\right]}}{n \, \log(n)}\]
