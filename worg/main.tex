% Created 2022-04-21 Thu 15:15
% Intended LaTeX compiler: pdflatex
\documentclass{report}
                              \usepackage[utf8]{inputenc}
\usepackage{xcolor}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,array}
\usepackage{booktabs}
\usepackage{natbib}
\usepackage{listings}
\newcommand{\J}{\ensuremath{J}}
\newcommand{\1}{\ensuremath{\mathbf{1}}}
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}
\newcommand{\h}{\ensuremath{\lambda}}
\newcommand{\indep}{\ensuremath{\perp\hspace*{-1.4ex}\perp}}
\newcommand{\T}{\ensuremath{\widetilde{T}}}
\newcommand{\X}{\ensuremath{{X}}}
\renewcommand{\t}{\ensuremath{\Tilde{t}}}
\newcommand{\ax}{\ensuremath{\mid a,\,{x}}}
\newcommand{\aX}{\ensuremath{\mid A = a,\,{X}}}
\newcommand{\AX}{\ensuremath{\mid A,\,{X}}}
\newcommand{\x}{\ensuremath{{x}}}
\newcommand{\trt}{\ensuremath{\pi^*}}
\newcommand{\tk}{\ensuremath{\tau}}
\newcommand{\lj}{\ensuremath{l}}
\newcommand{\jj}{\ensuremath{j}}
\newcommand{\tK}{\ensuremath{K}}
\newcommand{\tKi}{\ensuremath{k}}
\newcommand{\TK}{\ensuremath{\mathcal{T}}}
\newcommand{\g}{\ensuremath{\pi}}
\RequirePackage{tcolorbox}
\definecolor{lightGray}{gray}{0.98}
\definecolor{medioGray}{gray}{0.83}
\definecolor{mygray}{rgb}{.95, 0.95, 0.95}
\newcommand{\mybox}[1]{\vspace{.5em}\begin{tcolorbox}[boxrule=0pt,colback=mygray] #1 \end{tcolorbox}}

\lstset{
keywordstyle=\color{blue},
commentstyle=\color{red},stringstyle=\color[rgb]{0,.5,0},
literate={~}{$\sim$}{1},
basicstyle=\ttfamily\small,
columns=fullflexible,
breaklines=true,
breakatwhitespace=false,
numbers=left,
numberstyle=\ttfamily\tiny\color{gray},
stepnumber=1,
numbersep=10pt,
backgroundcolor=\color{white},
tabsize=4,
keepspaces=true,
showspaces=false,
showstringspaces=false,
xleftmargin=.23in,
frame=single,
basewidth={0.5em,0.4em},
}
\renewcommand*\familydefault{\sfdefault}
\itemsep2pt
\author{David Chen, Thomas Gerds, Helene Rytgaard}
\date{}
\title{ConCR-TMLE R Paper}
\begin{document}

\maketitle
\abstract{
An abstract of less than 150 words.
}

\section*{Introduction}
\label{sec:orgc7d06bf}

\section*{Data Structure}
\label{sec:org93562d0}

Consider a survival analysis on an interval \([0,\,t_{max}]\) with competing risks. Let \(T^a_j\) denote counterfactual time-to-event variables for event \(j\) and intervention \(a\), for competing events \(j \in \mathcal{J} = \{1, 2, \dots, J\}\) and an intervention \(a \in \mathcal{A}\). Our counterfactual data structure can then be denoted by
\[(T^a_j,\;\X\,:\;a\in\mathcal{A},\;j\in\mathcal{J})\]
where \(\X \in \mathbb{R}^d\) is a \(d\)-dimensional vector of baseline covariates. For a single time-point binary intervention, as in many randomized control trials, \(\mathcal{A} = \{0, 1\}\) and the corresponding counterfactual data is 
\[ (T^1_j,\; T^0_j,\;\X\,: \;j\in\mathcal{J})\]

\lstset{language=r,label= ,caption= ,captionpos=b,numbers=none,otherkeywords={}, deletekeywords={}}
\begin{lstlisting}
head(counterfactuals)
\end{lstlisting}

\begin{center}
\begin{tabular}{rrrrrrrr}
 & T.j1.a0 & T.j1.a1 & T.j2.a0 & T.j2.a1 & L1 & L2 & L3\\
\hline
1 & 0.1599887 & 0.4906215 & 0.5399409 & 0.5803671 & -1.7677221 & 4 & 3.0093952\\
2 & 1.1369533 & 1.9210028 & 0.2375033 & 0.9133089 & -0.4916921 & 0 & 0.3294865\\
3 & 0.3447736 & 1.2538906 & 0.4779721 & 0.8540658 & 0.3214659 & 3 & 4.1630246\\
4 & 4.6631762 & 0.3718961 & 1.5650534 & 0.2485393 & 1.4606608 & 3 & 1.5313713\\
5 & 0.1430018 & 0.5951058 & 0.3003895 & 0.9765322 & 1.5372426 & 2 & 1.5580743\\
6 & 1.8419819 & 3.9131870 & 1.8517334 & 3.0117075 & -0.3395685 & 4 & 0.8455748\\
\end{tabular}
\end{center}

Let \(O\) denote the corresponding coarsened observed data where \(O \sim P_0\). The observed data would include the time-to-censoring \(C\), and observed intervention \(A\). The time to first event (censoring or otherwise) we denote as \(\T = \min(C,\; T_j\,: \; j \in \mathcal{J})\) with \(\Delta = (\argmin\limits_j T_j) \times \1(\min\limits_j T_j \leq C)\) marking which outcome is observed (\(\Delta = 0\) being that censoring occurred). The observable right-censored survival data with competing events can then be represented as 
\[O = (\T,\;\Delta,\;A,\;\X)\]

\lstset{language=r,label= ,caption= ,captionpos=b,numbers=none,otherkeywords={}, deletekeywords={}}
\begin{lstlisting}
head(observed)
\end{lstlisting}

\begin{center}
\begin{tabular}{rrrrrrr}
 & T.tilde & Delta & A & L1 & L2 & L3\\
\hline
1 & 0.20711055 & 0 & 1 & -1.7677221 & 4 & 3.0093952\\
2 & 0.91147298 & 0 & 1 & -0.4916921 & 0 & 0.3294865\\
3 & 0.08374201 & 0 & 0 & 0.3214659 & 3 & 4.1630246\\
4 & 0.29772679 & 0 & 0 & 1.4606608 & 3 & 1.5313713\\
5 & 0.14300179 & 1 & 0 & 1.5372426 & 2 & 1.5580743\\
6 & 1.06839386 & 0 & 0 & -0.3395685 & 4 & 0.8455748\\
\end{tabular}
\end{center}

This observed data also allows the ``long-format'' formulation, where with single time-point intervention variable \(A\) and baseline covariate vector \(\X\), \[O = (N_j(t),\;N_c(t),\;A,\;\X\,:\, j\in\mathcal{J}, t \leq \T)\] Here \(N_j(t) = \1(\T \leq t, \Delta = j)\) and \(N_c(t) = \1(\T \leq t, \Delta = 0)\) denote counting processes for event \(j\) and censoring respectively.

Under coarsening at random (CAR), the observed data likelihood can be factorized as
\begin{align*}
p(O) = p&(\X)\, \g(A \mid \X)\, \lambda_c(\T \AX)^{\1(\Delta = 0)} S_c(\T\text{-} \AX)\\
&\prod_{j=1}^{J} S(\T\text{-} \AX) \, \lambda_j(\T \AX)^{\1(\Delta = j)}
\end{align*}
where \(\lambda_c(t \AX)\) is the hazard of the censoring process and \(\lambda_j(t \AX)\) is the hazard of the \(j^{th}\) event process. Additionally
\begin{align*}
    S_c(t \ax) &= \exp\left(-\int_{0}^{t} \lambda_c(s \ax) \,ds\right)
\intertext{while in a pure competing risks setting}
    S(t \ax) &= \exp\left(-\int_{0}^{t} \sum_{j=1}^{J} \lambda_j(s \ax) \,ds\right)
\intertext{and} 
    F_j(t \ax) &= \int_{0}^{t} S(s\text{-} \ax) \lambda_j(s \ax)\,ds\\
    &= \int_{0}^{t} \exp\bigg(-\int_{0}^{s} \sum_{j=1}^{J} \lambda_j(u \ax)\,du\bigg) \lambda_j(s \ax)\,ds.
\end{align*}

\section*{What is estimated?}
\label{sec:orgb4904da}

Given the identification assumptions of
\begin{enumerate}
\item Consistency : \(T = T^a\) when \(A = a\) for $a = 0,1$.
\item No unmeasured confounding: \(T^a \indep A \mid \X\) for $a = 0,1$.
\item Coarsening at random on censoring: \(T \indep C \AX\)
\end{enumerate}
the hypothetical distribution for data generated following a desired treatment regime involving \(A \sim \trt(A \mid \X)\) and the prevention of the censoring process can be identified as
\[p^{\trt}(O) = p(\X)\, \trt(A \mid \X)\, \prod_{j=1}^{J} S(\T\text{-} \AX) \lambda_j(\T \AX)^{\1(\Delta = j)}\]
For a target parameter of the cause \(\jj \in \J\) absolute risk at time \(\tk \in \TK \subseteq [0, t_{max}]\) under this treatment regime \(\trt\), the corresponding efficient influence function is
\begin{align*}
    D^{*}_{\trt, \jj, \tk}(P)(O) &= \sum_{j = 1}^{J} \int_{0}^{\tk} \bigg[h_{\trt, \jj, \lj, \tk, s}(P)(O) \left(N_j(ds) - \1(\T \geq s)\,\lambda_\lj(s \AX)\right) \bigg] \,ds\\[2mm]
    &\hspace{2cm}+ \sum_{a=0,1} F_\jj(t \mid A = a, \X)\,\trt(a \mid X) - \Psi_{\trt, \jj, \tk}(P_0)
\intertext{with the clever covariate}
h_{\trt, \jj, \lj, \tk, s}(P)(O) &= \frac{\trt(A \mid \X)\, \1(s \leq \tk)}{\g(A \mid \X) S_c(s\text{-} \AX)} \left(\1(\delta = \jj) - \frac{F_\jj(\tk \AX) - F_\jj(s \AX)}{S(s \AX)}\right)
\end{align*}

As the efficient influence function and clever covariates depend on the treatment distribution \g, the censoring survival function \(S_c\), and the event cause-specific hazards \(\lambda = (\lambda_\lj : j = 1, ..., J)\), we will in subsequent sections use the following alternative notation for clarity when appropriate:
\begin{align*}
D^{*}_{\trt, \jj, \tk}(\lambda, \g, S_c)(O) &= D^{*}_{\trt, \jj, \tk}(P)(O)\\
h_{\trt, \jj, \lj, \tk, s}(\lambda, \g, S_c)(O)&= h_{\trt, \jj, \lj, \tk, s}(P)(O)
\end{align*}

Therefore, to efficiently estimate survival-curve derived estimands such as the cause-specific absolute risks, the components of the data distribution that must be estimated are \(\g(A \mid \X)\), \(S_c(t \AX)\), \(\lambda_j(t \AX)\), \(F_j(t \AX)\), and \(S(t \AX)\)

\section*{Estimation}
\label{sec:org74b1667}
\subsection*{Cross-Validation Specification}
\label{sec:org3a2066a}
Let \(Q_n = \{O_i\}_{i=1}^n\) be an observed sample of \(n\) i.i.d observations of \(O \sim P_0\). For \(V\text{-fold}\) cross validation, let \(B_n = \{1, ... , V\}^n\) be a random vector that assigns the \(n\) observations into \(V\) validation folds. For each \(v \in \{1, ..., V\}\) we then define training set \(Q^\mathcal{T}_v = \{O_i : B_n(i) = v\}\) with the corresponding validation set \(Q^\mathcal{V}_v = \{O_i : B_n(i) \neq v\}\).

\subsubsection*{Stratified Cross-Validation}
\label{sec:org2510ea3}
\lstset{language=r,label= ,caption= ,captionpos=b,numbers=none,otherkeywords={}, deletekeywords={}}
\begin{lstlisting}
StrataIDs <- factor(paste(observed[["A"]], observed[["Delta"]]))
CVFolds <- origami::make_folds(n = observed,
			       fold_fun = origami::folds_vfold,
			       strata_ids = StrataIDs)
\end{lstlisting}


\subsection*{Propensity Score Estimation}
\label{sec:org95edd15}
For the true conditional distribution of \(A\) given \(\X\), \(\g_0(\cdot \mid \X)\), and \(\Hat{\g} : Q_n \to \Hat{\g}(Q_n)\), let \(L_\g\) be a loss function such that the risk \(\mathbb{E}_0\left[L_\g(\Hat{\g}, O)\right]\) is minimized when \(\Hat{\g} = \g_0\). For instance, with a binary \(A\), we may specify the negative log loss \(L_\g(\Hat{\g}, O) = \text{-}\log\left(\Hat{\g}(1 \mid \X)^A \; \Hat{\g}(0 \mid \X))^{1-A}\right)\). We can then define the discrete superlearner selector which chooses from a set of candidate models \(\mathcal{M_\g}\) the candidate propensity score model that has minimal cross validated risk 
\[ \Hat{\g}^{SL} = \argmin_{\Hat{\g} \in \mathcal{M}_\g} \sum_{v = 1}^{V} P_{Q^\mathcal{V}_v} \; L_\g(\Hat{\g}(Q^\mathcal{T}_v), Q^\mathcal{V}_v)\]

This discrete superlearner model \(\Hat{\g}^{SL}\) is then fitted on the full observed data \(Q_n\) and used to estimate \(\g_0(A \mid \X)\)

\lstset{language=r,label= ,caption= ,captionpos=b,numbers=none,otherkeywords={}, deletekeywords={}}
\begin{lstlisting}
CovDataTable <- observed[, -c("T.tilde", "Delta", "A")]
Model <- list("Trt" = sl3::make_learner(sl3:::Lrnr_glm))
Intervention <- list(
  "A=1" = list("intervention" = function(a, L) rep_len(1, length(a)),
	       "g.star" = function(a, L) {as.numeric(a == 1)}),
  "A=0" = list("intervention" = function(a, L) rep_len(0, length(a)),
	       "g.star" = function(a, L) {as.numeric(a == 0)})
)

Regime <- getRegime(Intervention = Intervention,
		    Treatment = observed[["A"]],
		    CovDataTable = CovDataTable)

PropScores <- getPropScore(Treatment = observed[["A"]],
			   CovDataTable = CovDataTable,
			   Model = Model,
			   MinNuisance = 0.05,
			   Regime = Regime,
			   PropScoreBackend = "sl3",
			   CVFolds = CVFolds)
TrtFit <- PropScores[["TrtFit"]]
PropScores <- PropScores[["PropScores"]]
\end{lstlisting}

\subsection*{Hazard Estimation}
\label{sec:orga95c995}
Let \(\lambda_{0,\,\delta}\) be the true censoring and cause-specific hazards when \(\delta = 0\) and \(\delta = 1, \dots, J\) respectively. Let \(\mathcal{M}_\delta\) for \(\delta = 0, \dots, J\) be the sets of candidate models, \(\{\Hat{\lambda}_\delta : Q_n \to \Hat{\lambda}_\delta(Q_n)\}\), for the censoring and cause-specific hazards and let \(L_\delta\) be loss functions such that the risks \(\mathbb{E}_0\left[L_\delta(\Hat{\lambda}_\delta, O)\right]\) are minimized when \(\Hat{\lambda}_\delta = \lambda_{0,\,\delta}\), for instance log likelihood loss. We can then define the discrete superlearner selectors for each \(\delta\) which choose from the set of candidate models \(\mathcal{M_\delta}\) the candidate propensity score model that has minimal cross validated risk 
\[ \Hat{\lambda}_\delta^{SL} = \argmin_{\Hat{\lambda}_\delta \in \mathcal{M}_\delta} \sum_{v = 1}^{V} P_{Q^\mathcal{V}_v} \; L_\g(\Hat{\lambda}_\delta(Q^\mathcal{T}_v), Q^\mathcal{V}_v)\]

These discrete superlearner selections \(\Hat{\lambda}_\delta^{SL}\) are then fitted on the full observed data \(Q_n\) and used to estimate \(\lambda_\delta(t \AX), \, F_\delta(t \AX),\, S(t \AX), \text{ and } S_c(t\text{-} \AX)\) for \(j = 1,\dots, J\).

\lstset{language=r,label= ,caption= ,captionpos=b,numbers=none,otherkeywords={}, deletekeywords={}}
\begin{lstlisting}
EventTime <- observed$`T.tilde`
TargetTime <- mean(EventTime)
Model <- list("0" = list(mod1 = Surv(T.tilde, Delta == 0) ~ A + L1 + L2),
	      "1" = list(mod1 = Surv(T.tilde, Delta == 1) ~ A + L1 + L2*L3))
TargetEvent <- 1:2
MinNuisance <- 0.05
Censored <- TRUE

HazTimes <- sort(unique(c(TargetTime, EventTime)))
HazTimes <- HazTimes[HazTimes <= max(TargetTime)]
Hazards <- data.table("Time" = c(0, HazTimes))

HazFits <- getHazFit(Data = observed,
		     EventTime = EventTime,
		     Model = Model,
		     CVFolds = CVFolds,
		     Hazards = Hazards)
HazSurvPreds <- getHazSurvPred(Data = observed,
			       HazFits = HazFits,
			       MinNuisance = MinNuiscance,
			       TargetEvent = TargetEvent,
			       TargetTime = TargetTime,
			       Regime = Regime,
			       Censored = Censored)
\end{lstlisting}

\subsubsection*{Lagged Censoring Survival}
\label{sec:org2c73ed2}
Let \(\mathcal{S}\) be the set containing all target and observed event times, ordered such that \(s_1 < s_2 < \dots s_{max}\). Then for all \(s_{\tK} \,\in\, \mathcal{S}\) we compute
\begin{align*}
\Hat{S}_c(s_{\tK}\text{-} \AX) &= \exp \left(\text{-} \sum_{\tKi = 1}^{\tK-1} \Hat{\lambda}_c^{SL}(s_{\tKi} \AX)\right) \\
&= \exp\left(\text{-} \int_{0}^{\tK\text{-}} \Hat\lambda^{SL}_c(s \AX) ds\right)\\
\end{align*}

\subsubsection*{Cause-Specific Hazards, Event-Free Survival, and Cause-Specific Absolute Risks}
\label{sec:orgb25e5fa}
For \(\lj = 1,\dots,J\) and \({\tK} \,\in\, \mathcal{S}\), the super learner selections \(\Hat\lambda_\lj^{SL}\) are fit on the full observed data \(Q_n\), and used to compute the event free survival
\begin{align*}
\Hat S(s_{\tK} \AX) &= \exp\left(\text{-} \sum_{{\tKi} = 1}^{\tK} \sum_{\lj = 1}^{J} \Hat\lambda^{SL}_\lj(s_{\tKi} \AX) \right)\\
&= \exp\left(\text{-} \int_{0}^{\tK} \sum_{\lj = 1}^{J} \Hat\lambda^{SL}_\lj(s \AX) ds\right)
\intertext{cause-specific absolute risks}
\Hat F_\lj(s_{\tK} \AX) &= \sum_{{\tKi} = 1}^{\tK} \Hat S(s_{\tKi} \AX) \, \Hat\lambda^{SL}_\lj(s_{\tKi} \AX)
\end{align*}

\section*{Computing the Efficient Influence Function}
\label{sec:orged81899}
For each desired treatment regime \(\trt\), each target time \tk, and each target event \jj, the efficient influence functions for each individual are computed in parts.

\subsection*{Clever Covariate \(h_{\trt, \jj, \lj, \tk, s}(O)\)}
\label{sec:orgeace9df}
For \(\lj = 1,\dots, J\) and \(s \,\in\, \mathcal{S}\), the stored cause-specific hazards \(\Hat\lambda^{SL}_\lj(s \AX)\) and event-free survival \(\Hat S(s \AX)\) are used to calculate the cause-specific absolute risks \(\Hat F_\lj(s \AX)\), then combined with the nuisance weight to calculate the clever covariates.
\begin{align*}
    h_{\trt,\, \jj,\, \lj,\, \tk,\, s}&(\Hat \lambda, \Hat \g, \Hat S_c)(O) = \\[2mm]
&\frac{{\color{blue}\trt(A \mid \X)\,} \1(s \leq \tk)}{{\color{green!70!black}\Hat\g^{SL}(A \mid \X) \;
\Hat S_c(s\text{-} \AX)}} \, \bigg(\1(\Delta = \jj) - \frac{{\color{red}\Hat F_\jj(\tk \AX)} - {\color{red}\Hat F_\jj(s \AX)}}{{\color{red}\Hat S(s \AX)}}\bigg)
\end{align*}

The clever covariate is a function of the {\color{blue}desired intervention density}, the {\color{green!70!black} observed intervention densities}, and the {\color{red}non-intervention outcome densities}.

1 clever covariate value for every individual, for every regime of interest, for every target event, for every target time, at every time \(s \,\in\, \mathcal{S}\).

\subsection*{Estimating the EIC}
\label{sec:orgd2490d9}
\begin{align*}
    D^*_{\trt, \jj, \tk}(\Hat \lambda, \Hat \g, \Hat S_c)(O) &= \sum_{\lj = 1}^{J} \sum_{\tKi = 1}^{\tK} \;  h_{\trt,\, \jj,\, \lj,\, \tk, s}(\Hat \lambda, \Hat \g, \Hat S_c)(O) \\
&\hspace{2cm}\left(\1(\Delta = \jj, \T = s_{\tKi}) - \1(\T \geq s_\tK) \, \Hat \lambda_\lj(s_{\tKi} \AX)\right)\\[2mm]
    &\hspace{5mm}{\color{blue!60!black}+ \sum_{a\,\in\,\mathcal{A}} F_\jj(\tk \mid A = a, \X)\,\trt(a \mid \X) - \Psi_{\trt, \jj, \tk}(P_0)}
\end{align*}

The sum over time and sum over events are done per individual. The addition of the absolute risk and subtraction of the target estimand are done later, outside of the loop over individuals.

1 EIC estimate for every individual, every regime of interest, every target event, and every target time.

\section*{TMLE one-step update}
\label{sec:orgadf891a}
Let \(D^*\) be the vector of efficient influence functions
\begin{align*}
D^{*}(\lambda, \g, S_c)(O) &= \left(D^*_{\trt, \jj, \tk}(\lambda, \g, S_c)(O) : \trt \in \mathcal{A}, \jj \in \mathcal{J}, \tk \in \TK)\right)
\intertext{and let \(h_{j, s}\) be the vector of clever covariates}
h_{j, s}(\lambda, \g, S_c)(O) &= \left(h_{\trt, \jj, \lj, \tk, s}(\lambda, \g, S_c)(O) : \trt \in \mathcal{A}, \jj \in \mathcal{J}, \tk \in \TK)\right)
\end{align*}
The one-step TMLE involves updating the cause-specific hazards along the universal least favorable submodel. This is implemented by updating the hazards in small steps along the sequence of locally-least favorable submodels in the following manner:
\[ \Hat \lambda_{j, \epsilon^d}(t) = \Hat\lambda^{SL}_{j}(t) \, \exp\left(\sum_{i = 1}^{d}\frac{\left<\mathbb{P}_n D^*(\Hat \lambda_{\epsilon^i}, \Hat \g, \Hat S_c)(O),\; h_{j, s}(\Hat \lambda_{\epsilon^i}, \Hat \g, \Hat S_c)(O) \right>_{\Sigma}}{|| D^*(\Hat \lambda_{\epsilon^i}, \Hat \g, \Hat S_c)(O)||_{\Sigma}} \; \epsilon \right)\]
where
\[ \left<x, y\right>_{\Sigma} = x^\top \Sigma^{\text{ -}1} y \hspace{.5cm}, \hspace{.5cm} ||x||_{\Sigma} = \sqrt{x^\top \Sigma^{\text{ -}1} x} \]

The default value of \(\epsilon\) in the software is 0.1, and the algorithm stops at \(\epsilon^i\) when
\[\mathbb{P}_n D^*(\Hat \lambda_{\epsilon^i}, \Hat \g, \Hat S_c)(O) \leq \frac{\sqrt{\mathbb{P}_n \left[D^*(\Hat \lambda_{\epsilon^i}, \Hat \g, \Hat S_c)(O)^2\right]}}{\sqrt{n} \, \log(n)}\]
\end{document}